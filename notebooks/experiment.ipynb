{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sweep_definition.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msweep_definition.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      7\u001b[0m     sweep_config \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(file)\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sweep_definition.yaml'"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "with open('sweep_definition.yaml', 'r') as file:\n",
    "    sweep_config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sweep_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 33\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m     32\u001b[0m search_space \u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[43msweep_config\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_space\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector_store\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     35\u001b[0m         grid \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sweep_config' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def flatten_dict(variant_dict):\n",
    "    variant_name = list(variant_dict.keys())[0]\n",
    "    variant_values = variant_dict[variant_name]\n",
    "    result_dict = {'variant_name': variant_name}\n",
    "    result_dict.update(variant_values)\n",
    "    return result_dict\n",
    "\n",
    "def cartesian_product(*lists):\n",
    "    cartesian_product = []\n",
    "    for items in itertools.product(*lists):\n",
    "        merged_dict = {}\n",
    "        for item in items:\n",
    "            merged_dict.update(item)\n",
    "        cartesian_product.append(merged_dict)\n",
    "    return cartesian_product\n",
    "\n",
    "def duplicate_dict(dictionary):\n",
    "    result = [dictionary]\n",
    "    for key, value in dictionary.items():\n",
    "        if isinstance(value, list):\n",
    "            temp_result = []\n",
    "            for item in value:\n",
    "                for res in result:\n",
    "                    temp_dict = res.copy()\n",
    "                    temp_dict[key] = item\n",
    "                    temp_result.append(temp_dict)\n",
    "            result = temp_result\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "search_space =[]\n",
    "for node in sweep_config.get('search_space'):\n",
    "    if node in ['llm','embedding','vector_store']:\n",
    "        grid = []\n",
    "        node_values = sweep_config.get('search_space').get(node)\n",
    "        for variant in node_values:\n",
    "            step_dict ={}\n",
    "            step_dict[node] = flatten_dict(variant)\n",
    "            grid.append(step_dict)\n",
    "        grid_final = []\n",
    "        for step in grid:\n",
    "            \n",
    "            node_id = list(step.keys())[0]    \n",
    "            fixed = {key:value for key,value in step.get(node_id).items() if not isinstance(value, dict)}\n",
    "            for key, value in step.get(node_id).items():\n",
    "                option_list =[]\n",
    "                if isinstance(value, dict):\n",
    "                    options = duplicate_dict(value)\n",
    "                    for option in options:\n",
    "                        f = deepcopy(fixed)\n",
    "                        f[key] = option.get('values')\n",
    "                        option_list.append(f)    \n",
    "            \n",
    "            if len(option_list)>1:\n",
    "                for opt in option_list:\n",
    "                    grid_final.append({node_id: opt})\n",
    "            else:\n",
    "                grid_final.append({node_id: fixed})\n",
    "        search_space.append(grid_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_steps = cartesian_product(*search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llm': {'variant_name': 'mistral',\n",
       "  'family': 'MISTRAL',\n",
       "  'connection': 'mistral-large-maas'},\n",
       " 'embedding': {'variant_name': 'aoai',\n",
       "  'family': 'AZUREOPENAI',\n",
       "  'connection': 'aoai',\n",
       "  'deployment': 'text-embedding-ada-002'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_steps[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "\n",
    "file_path = \"./flow_template/cookiecutter_template.json\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white_kiwi_usxrw2ck\n"
     ]
    }
   ],
   "source": [
    "from unique_names_generator import get_random_name\n",
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "def generate_step_id():\n",
    "    name = get_random_name(separator=\"_\", style=\"lowercase\")\n",
    "    unique_id = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))\n",
    "    return name+'_'+ unique_id\n",
    "\n",
    "# Generate a unique ID\n",
    "unique_id = generate_step_id()\n",
    "print(unique_id)\n",
    "\n",
    "\n",
    "def create_cookiecutter(data, grid_step):\n",
    "    data_dict = deepcopy(data)\n",
    "    for node_id in data_dict:\n",
    "        if node_id in ['llm','embedding','vector_store'] and node_id in grid_step.keys():\n",
    "            data_dict[node_id]=grid_step[node_id]\n",
    "        elif node_id in ['llm','embedding','vector_store'] and node_id not in grid_step.keys():\n",
    "            del data_dict[node_id]\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_path = \"./flow_template/cookiecutter.json\"\n",
    "\n",
    "for i, search_step_dict in enumerate(grid_search_steps):\n",
    "    directory = 'flow_versions'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    step_dict = create_cookiecutter(data, search_step_dict)\n",
    "    step_dict[\"flow_name\"] = f\"grid_step_{i}\"\n",
    "    \n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(step_dict, file, indent=4)\n",
    "    \n",
    "    subprocess.run([\"cd ./flow_versions && cookiecutter ../flow_template --no-input --skip-if-file-exists\"], shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting promptflow\n",
      "  Downloading promptflow-1.9.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting promptflow-core==1.9.0 (from promptflow)\n",
      "  Downloading promptflow_core-1.9.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting promptflow-devkit==1.9.0 (from promptflow)\n",
      "  Downloading promptflow_devkit-1.9.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting promptflow-tracing==1.9.0 (from promptflow)\n",
      "  Downloading promptflow_tracing-1.9.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting docutils!=0.21.post1 (from promptflow-core==1.9.0->promptflow)\n",
      "  Downloading docutils-0.21.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting filetype>=1.2.0 (from promptflow-core==1.9.0->promptflow)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: flask<4.0.0,>=2.2.3 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from promptflow-core==1.9.0->promptflow) (3.0.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from promptflow-core==1.9.0->promptflow) (4.20.0)\n",
      "Requirement already satisfied: psutil in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from promptflow-core==1.9.0->promptflow) (5.9.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1.0 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from promptflow-core==1.9.0->promptflow) (2.8.2)\n",
      "Collecting ruamel.yaml<1.0.0,>=0.17.10 (from promptflow-core==1.9.0->promptflow)\n",
      "  Using cached ruamel.yaml-0.18.6-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: argcomplete>=3.2.3 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from promptflow-devkit==1.9.0->promptflow) (3.3.0)\n",
      "Collecting azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 (from promptflow-devkit==1.9.0->promptflow)\n",
      "  Downloading azure_monitor_opentelemetry_exporter-1.0.0b24-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from promptflow-devkit==1.9.0->promptflow) (0.4.6)\n",
      "Collecting cryptography>=42.0.4 (from promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached cryptography-42.0.5-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.4.0 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from promptflow-devkit==1.9.0->promptflow) (3.13.1)\n",
      "Collecting flask-cors<5.0.0,>=4.0.0 (from promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached Flask_Cors-4.0.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting flask-restx<2.0.0,>=1.2.0 (from promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached flask_restx-1.3.0-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: gitpython<4.0.0,>=3.1.24 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from promptflow-devkit==1.9.0->promptflow) (3.1.41)\n",
      "Collecting httpx>=0.25.1 (from promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting keyring<25.0.0,>=24.2.0 (from promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached keyring-24.3.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.5 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from promptflow-devkit==1.9.0->promptflow) (3.20.2)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_http-1.24.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.5.3 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from promptflow-devkit==1.9.0->promptflow) (2.1.4)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.1.0 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from promptflow-devkit==1.9.0->promptflow) (10.2.0)\n",
      "Requirement already satisfied: pydash<8.0.0,>=6.0.0 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from promptflow-devkit==1.9.0->promptflow) (7.0.5)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.0 (from promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.48 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from promptflow-devkit==1.9.0->promptflow) (2.0.25)\n",
      "Requirement already satisfied: strictyaml<2.0.0,>=1.5.0 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from promptflow-devkit==1.9.0->promptflow) (1.7.3)\n",
      "Requirement already satisfied: tabulate<1.0.0,>=0.9.0 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from promptflow-devkit==1.9.0->promptflow) (0.9.0)\n",
      "Collecting waitress<3.0.0,>=2.1.2 (from promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached waitress-2.1.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting openai (from promptflow-tracing==1.9.0->promptflow)\n",
      "  Downloading openai-1.20.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from promptflow-tracing==1.9.0->promptflow)\n",
      "  Using cached opentelemetry_sdk-1.24.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tiktoken>=0.4.0 (from promptflow-tracing==1.9.0->promptflow)\n",
      "  Using cached tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.9.0->promptflow) (1.29.6)\n",
      "Collecting fixedint==0.1.6 (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached fixedint-0.1.6-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: msrest>=0.6.10 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.9.0->promptflow) (0.7.1)\n",
      "Collecting opentelemetry-api~=1.21 (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached opentelemetry_api-1.24.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting psutil (from promptflow-core==1.9.0->promptflow)\n",
      "  Using cached psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from cryptography>=42.0.4->promptflow-devkit==1.9.0->promptflow) (1.16.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.9.0->promptflow) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.9.0->promptflow) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.9.0->promptflow) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.9.0->promptflow) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.9.0->promptflow) (1.7.0)\n",
      "Collecting aniso8601>=0.82 (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: pytz in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit==1.9.0->promptflow) (2023.3.post1)\n",
      "Collecting importlib-resources (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from gitpython<4.0.0,>=3.1.24->promptflow-devkit==1.9.0->promptflow) (4.0.11)\n",
      "Requirement already satisfied: anyio in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from httpx>=0.25.1->promptflow-devkit==1.9.0->promptflow) (4.2.0)\n",
      "Requirement already satisfied: certifi in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from httpx>=0.25.1->promptflow-devkit==1.9.0->promptflow) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.1->promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from httpx>=0.25.1->promptflow-devkit==1.9.0->promptflow) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from httpx>=0.25.1->promptflow-devkit==1.9.0->promptflow) (1.3.0)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.25.1->promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core==1.9.0->promptflow) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core==1.9.0->promptflow) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core==1.9.0->promptflow) (0.32.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core==1.9.0->promptflow) (0.17.1)\n",
      "Collecting jaraco.classes (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached jaraco.classes-3.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.11.4 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.9.0->promptflow) (7.0.1)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.9.0->promptflow) (3.3.3)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.9.0->promptflow) (0.8.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.5->promptflow-devkit==1.9.0->promptflow) (23.2)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.9.0->promptflow) (1.62.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached opentelemetry_proto-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests~=2.7 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.9.0->promptflow) (2.31.0)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.19 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from opentelemetry-proto==1.24.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.9.0->promptflow) (4.25.2)\n",
      "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.9.0->promptflow)\n",
      "  Using cached opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.9.0->promptflow) (4.9.0)\n",
      "Collecting importlib-metadata>=4.11.4 (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached importlib_metadata-7.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from pandas<3.0.0,>=1.5.3->promptflow-devkit==1.9.0->promptflow) (1.26.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from pandas<3.0.0,>=1.5.3->promptflow-devkit==1.9.0->promptflow) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1.0->promptflow-core==1.9.0->promptflow) (1.16.0)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml<1.0.0,>=0.17.10->promptflow-core==1.9.0->promptflow)\n",
      "  Using cached ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit==1.9.0->promptflow) (3.0.3)\n",
      "Collecting regex>=2022.1.18 (from tiktoken>=0.4.0->promptflow-tracing==1.9.0->promptflow)\n",
      "  Downloading regex-2024.4.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: distro<2,>=1.7.0 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from openai->promptflow-tracing==1.9.0->promptflow) (1.9.0)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai->promptflow-tracing==1.9.0->promptflow)\n",
      "  Downloading pydantic-2.7.0-py3-none-any.whl.metadata (103 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>4 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from openai->promptflow-tracing==1.9.0->promptflow) (4.66.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from anyio->httpx>=0.25.1->promptflow-devkit==1.9.0->promptflow) (1.2.0)\n",
      "Requirement already satisfied: pycparser in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=42.0.4->promptflow-devkit==1.9.0->promptflow) (2.21)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.9.0->promptflow) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit==1.9.0->promptflow) (5.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from importlib-metadata>=4.11.4->keyring<25.0.0,>=24.2.0->promptflow-devkit==1.9.0->promptflow) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from Jinja2>=3.1.2->flask<4.0.0,>=2.2.3->promptflow-core==1.9.0->promptflow) (2.1.3)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.9.0->promptflow) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.9.0->promptflow) (1.3.1)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai->promptflow-tracing==1.9.0->promptflow)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.1 (from pydantic<3,>=1.9.0->openai->promptflow-tracing==1.9.0->promptflow)\n",
      "  Downloading pydantic_core-2.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.9.0->promptflow) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.9.0->promptflow) (2.0.7)\n",
      "Collecting more-itertools (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit==1.9.0->promptflow)\n",
      "  Using cached more_itertools-10.2.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/vhoudebine/miniconda3/envs/python310/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.9.0->promptflow) (3.2.2)\n",
      "Downloading promptflow-1.9.0-py3-none-any.whl (18 kB)\n",
      "Downloading promptflow_core-1.9.0-py3-none-any.whl (946 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m946.9/946.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading promptflow_devkit-1.9.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading promptflow_tracing-1.9.0-py3-none-any.whl (22 kB)\n",
      "Downloading azure_monitor_opentelemetry_exporter-1.0.0b24-py2.py3-none-any.whl (136 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.0/136.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached fixedint-0.1.6-py3-none-any.whl (12 kB)\n",
      "Using cached cryptography-42.0.5-cp39-abi3-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "Downloading docutils-0.21.1-py3-none-any.whl (587 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.4/587.4 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached Flask_Cors-4.0.0-py2.py3-none-any.whl (14 kB)\n",
      "Using cached flask_restx-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached keyring-24.3.1-py3-none-any.whl (38 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_http-1.24.0-py3-none-any.whl (16 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
      "Using cached opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
      "Using cached opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
      "Using cached psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
      "Using cached tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "Using cached waitress-2.1.2-py3-none-any.whl (57 kB)\n",
      "Downloading openai-1.20.0-py3-none-any.whl (292 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
      "Downloading pydantic-2.7.0-py3-none-any.whl (407 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.9/407.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.4.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
      "Using cached importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Using cached jaraco.classes-3.4.0-py3-none-any.whl (6.8 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached more_itertools-10.2.0-py3-none-any.whl (57 kB)\n",
      "Installing collected packages: fixedint, filetype, aniso8601, waitress, ruamel.yaml.clib, regex, python-dotenv, pydantic-core, psutil, opentelemetry-semantic-conventions, opentelemetry-proto, more-itertools, importlib-resources, importlib-metadata, h11, docutils, deprecated, annotated-types, tiktoken, ruamel.yaml, pydantic, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jaraco.classes, httpcore, cryptography, opentelemetry-sdk, httpx, flask-cors, opentelemetry-exporter-otlp-proto-http, openai, keyring, flask-restx, azure-monitor-opentelemetry-exporter, promptflow-tracing, promptflow-core, promptflow-devkit, promptflow\n",
      "  Attempting uninstall: python-dotenv\n",
      "    Found existing installation: python-dotenv 0.21.0\n",
      "    Uninstalling python-dotenv-0.21.0:\n",
      "      Successfully uninstalled python-dotenv-0.21.0\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.7\n",
      "    Uninstalling psutil-5.9.7:\n",
      "      Successfully uninstalled psutil-5.9.7\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 7.0.1\n",
      "    Uninstalling importlib-metadata-7.0.1:\n",
      "      Successfully uninstalled importlib-metadata-7.0.1\n",
      "  Attempting uninstall: cryptography\n",
      "    Found existing installation: cryptography 41.0.7\n",
      "    Uninstalling cryptography-41.0.7:\n",
      "      Successfully uninstalled cryptography-41.0.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "azure-storage-file-datalake 12.14.0 requires azure-storage-blob<13.0.0,>=12.19.0, but you have azure-storage-blob 12.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aniso8601-9.0.1 annotated-types-0.6.0 azure-monitor-opentelemetry-exporter-1.0.0b24 cryptography-42.0.5 deprecated-1.2.14 docutils-0.21.1 filetype-1.2.0 fixedint-0.1.6 flask-cors-4.0.0 flask-restx-1.3.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 importlib-metadata-7.0.0 importlib-resources-6.4.0 jaraco.classes-3.4.0 keyring-24.3.1 more-itertools-10.2.0 openai-1.20.0 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-http-1.24.0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 promptflow-1.9.0 promptflow-core-1.9.0 promptflow-devkit-1.9.0 promptflow-tracing-1.9.0 psutil-5.9.8 pydantic-2.7.0 pydantic-core-2.18.1 python-dotenv-1.0.1 regex-2024.4.16 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 tiktoken-0.6.0 waitress-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install promptflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/vhoudebine/config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from promptflow.azure import PFClient\n",
    "\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "  \n",
    "# Get a handle to workspace, it will use config.json in current and parent directory.\n",
    "pf = PFClient.from_config(\n",
    "    credential=credential\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search_steps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Create a thread for each dictionary\u001b[39;00m\n\u001b[1;32m     21\u001b[0m runs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, search_step_dict \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mgrid_search_steps\u001b[49m)[:\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     23\u001b[0m     run \u001b[38;5;241m=\u001b[39m create_and_run_flow(i)\n\u001b[1;32m     24\u001b[0m     runs\u001b[38;5;241m.\u001b[39mappend(run)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_search_steps' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_and_run_flow(i):\n",
    "    # Apply your function to the dictionary here\n",
    "    flow = os.path.join(\"./flow_versions\", f\"rag_flow_grid_step_{i}\")\n",
    "    data =\"./evaluation_data/data.jsonl\"\n",
    "    print(f\"Creating run for {flow}\")\n",
    "    # create run\n",
    "    base_run = pf.run(\n",
    "        flow=flow,\n",
    "        data=data,\n",
    "        column_mapping={\n",
    "        \"question\": \"${data.question}\"\n",
    "        }\n",
    "    )\n",
    "    print(f\"Created run {base_run.name}\")\n",
    "    return base_run\n",
    "\n",
    "\n",
    "# Create a thread for each dictionary\n",
    "runs = []\n",
    "for i, search_step_dict in enumerate(grid_search_steps)[:1]:\n",
    "    run = create_and_run_flow(i)\n",
    "    runs.append(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Failed'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.runs.get('rag_flow_grid_step_2_variant_0_20240415_170950_374378').status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = pf.runs.get('rag_flow_grid_step_2_variant_0_20240415_170950_374378')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rag_flow_grid_step_2_variant_0_20240415_170950_374378'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get run results and store them\n",
    "run.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['e','b'].count('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from flowgrid import utils\n",
    "\n",
    "#utils.get_run_info('rag_flow_grid_step_2_variant_0_20240415_170950_374378')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_output_asset_id() missing 1 required positional argument: 'asset_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_output_asset_id\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrag_flow_grid_step_2_variant_0_20240415_170950_374378\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_output_asset_id() missing 1 required positional argument: 'asset_name'"
     ]
    }
   ],
   "source": [
    "utils.get_output_asset_id('rag_flow_grid_step_2_variant_0_20240415_170950_374378')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('rag_flow_grid_step_2_variant_0_20240415_170950_374378', None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "utils.get_run_info('rag_flow_grid_step_2_variant_0_20240415_170950_374378')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = pf.runs.get('rag_flow_grid_step_2_variant_0_20240415_170950_374378')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'azureml.promptflow.runtime_name': 'automatic',\n",
       " 'azureml.promptflow.inputs_mapping': '{\"question\":\"${data.question}\"}',\n",
       " 'azureml.promptflow.disable_trace': 'false',\n",
       " 'azureml.promptflow.session_id': '7b022dbbad3617f8db5c31906032b7f3ec900b3306cecc4a',\n",
       " 'azureml.promptflow.definition_file_name': 'flow.dag.yaml',\n",
       " 'azureml.promptflow.flow_lineage_id': '536aaae1360552919ad7489ec59e4ada907dc5606d3b3fe5bd11747b63999c0d',\n",
       " 'azureml.promptflow.flow_definition_datastore_name': 'workspaceblobstore',\n",
       " 'azureml.promptflow.flow_definition_blob_path': 'LocalUpload/d620a9ee65156b304f000ec623a87e7f/rag_flow_grid_step_2/flow.dag.yaml',\n",
       " '_azureml.evaluation_run': 'promptflow.BatchRun',\n",
       " 'azureml.promptflow.snapshot_id': '86934ceb-ad40-4838-9f0d-36002686d6c4',\n",
       " 'azureml.promptflow.runtime_version': '20240411.v4'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "tenant_id = \"16b3c013-d300-468d-ac64-7eda0820b6d3\"\n",
    "subscription_id = \"6c065ea7-65cd-4a34-8e2a-3e21ad4a8e9f\"\n",
    "resource_group = \"vince-rg\"\n",
    "workspace_name = \"vince-dev\"\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "ws = Workspace.get(workspace_name, subscription_id=subscription_id, resource_group=resource_group, auth=interactive_auth)\n",
    "region = ws.location\n",
    "default_datastore = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eastus'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationException",
     "evalue": "AuthenticationException:\n\tMessage: azure-cli package is not installed. AzureCliAuthentication requires azure-cli>=2.30.0 to be installed in the same python environment where azureml-sdk is installed.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"inner_error\": {\n            \"code\": \"Authentication\"\n        },\n        \"message\": \"azure-cli package is not installed. AzureCliAuthentication requires azure-cli>=2.30.0 to be installed in the same python environment where azureml-sdk is installed.\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.11/site-packages/azureml/core/authentication.py:1009\u001b[0m, in \u001b[0;36mAzureCliAuthentication._azure_cli_core_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_profile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Profile  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'azure.cli'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAuthenticationException\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazureml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauthentication\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureCliAuthentication\n\u001b[0;32m----> 3\u001b[0m cli_auth \u001b[38;5;241m=\u001b[39m \u001b[43mAzureCliAuthentication\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m ws \u001b[38;5;241m=\u001b[39m Workspace(subscription_id\u001b[38;5;241m=\u001b[39msubscription_id,\n\u001b[1;32m      6\u001b[0m                resource_group\u001b[38;5;241m=\u001b[39mresource_group,\n\u001b[1;32m      7\u001b[0m                workspace_name\u001b[38;5;241m=\u001b[39m workspace_name,\n\u001b[1;32m      8\u001b[0m                auth\u001b[38;5;241m=\u001b[39mcli_auth)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound workspace \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m at location \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ws\u001b[38;5;241m.\u001b[39mname, ws\u001b[38;5;241m.\u001b[39mlocation))\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.11/site-packages/azureml/core/authentication.py:811\u001b[0m, in \u001b[0;36mAzureCliAuthentication.__init__\u001b[0;34m(self, cloud)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Class Azure Cli Authentication constructor.\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \n\u001b[1;32m    805\u001b[0m \u001b[38;5;124;03m:param cloud: The name of the target cloud. Can be one of \"AzureCloud\", \"AzureChinaCloud\", or\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;124;03m:type cloud: str\u001b[39;00m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28msuper\u001b[39m(AzureCliAuthentication, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(cloud)\n\u001b[0;32m--> 811\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_azure_cli_core_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/openai/lib/python3.11/site-packages/azureml/core/authentication.py:1020\u001b[0m, in \u001b[0;36mAzureCliAuthentication._azure_cli_core_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m ver \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AuthenticationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mazure-cli package is not installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m                                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAzureCliAuthentication requires azure-cli>=2.30.0 to be installed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1022\u001b[0m                                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the same python environment where azureml-sdk is installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parse_version(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2.30.0\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m>\u001b[39m parse_version(ver):\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AuthenticationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAzureCliAuthentication requires azure-cli>=2.30.0 to be installed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1025\u001b[0m                                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the same python environment where azureml-sdk is installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAuthenticationException\u001b[0m: AuthenticationException:\n\tMessage: azure-cli package is not installed. AzureCliAuthentication requires azure-cli>=2.30.0 to be installed in the same python environment where azureml-sdk is installed.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"inner_error\": {\n            \"code\": \"Authentication\"\n        },\n        \"message\": \"azure-cli package is not installed. AzureCliAuthentication requires azure-cli>=2.30.0 to be installed in the same python environment where azureml-sdk is installed.\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core.authentication import AzureCliAuthentication\n",
    "\n",
    "cli_auth = AzureCliAuthentication()\n",
    "\n",
    "ws = Workspace(subscription_id=subscription_id,\n",
    "               resource_group=resource_group,\n",
    "               workspace_name= workspace_name,\n",
    "               auth=cli_auth)\n",
    "\n",
    "print(\"Found workspace {} at location {}\".format(ws.name, ws.location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "subscription_id = os.environ.get(\"AZURE_SUBSCRIPTION_ID\")\n",
    "resource_group = os.environ.get(\"AZURE_RESOURCE_GROUP\")\n",
    "workspace_name = os.environ.get(\"AZURE_WORKSPACE_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source ../.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AzureBlobDatastore({'type': <DatastoreType.AZURE_BLOB: 'AzureBlob'>, 'name': 'workspaceblobstore', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/6c065ea7-65cd-4a34-8e2a-3e21ad4a8e9f/resourceGroups/vince-rg/providers/Microsoft.MachineLearningServices/workspaces/vince-dev/datastores/workspaceblobstore', 'Resource__source_path': '', 'base_path': '/home/vhoudebine/projects/pf-models-evaluation/notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fbfdc0cb050>, 'credentials': {'type': 'account_key'}, 'container_name': 'azureml-blobstore-6184be4d-8f14-4f56-b031-56a6ec3813fc', 'account_name': 'vincedev4106797923', 'endpoint': 'core.windows.net', 'protocol': 'https'})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id = subscription_id,\n",
    "    resource_group_name = resource_group,\n",
    "    workspace_name = workspace_name,\n",
    ")\n",
    "\n",
    "ml_client.datastores.get_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_ws = ml_client.workspaces.get(workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml_ws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_name = \"debug_info\"\n",
    "run_id = \"rag_flow_grid_step_3_variant_0_20240417_111404_012615\"\n",
    "\n",
    "def download_artifacts(run_id, asset_name, ws):\n",
    "    import requests\n",
    "    import os\n",
    "    if region == \"centraluseuap\":\n",
    "        url = f\"https://int.api.azureml-test.ms/history/v1.0/subscriptions/{subscription_id}/resourceGroups/{resource_group}/providers/Microsoft.MachineLearningServices/workspaces/{workspace_name}/rundata\"\n",
    "    else:\n",
    "        url = f\"https://ml.azure.com/api/{region}/history/v1.0/subscriptions/{subscription_id}/resourceGroups/{resource_group}/providers/Microsoft.MachineLearningServices/workspaces/{workspace_name}/rundata\"\n",
    "        payload = {\n",
    "            \"runId\": run_id,\n",
    "            \"selectRunMetadata\": True\n",
    "        }\n",
    "    response = requests.post(url, json=payload, headers=ws._auth.get_authentication_header())\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to get output asset id for run {run_id} because RunHistory API returned status code {response.status_code}. Response: {response.text}\")\n",
    "    output_asset_id = response.json()[\"runMetadata\"][\"outputs\"][asset_name][\"assetId\"]\n",
    "    if region == \"centraluseuap\":\n",
    "        url = f\"https://int.api.azureml-test.ms/data/v1.0/subscriptions/{subscription_id}/resourceGroups/{resource_group}/providers/Microsoft.MachineLearningServices/workspaces/{workspace_name}/dataversion/getByAssetId\"\n",
    "    else:\n",
    "        url = f\"https://ml.azure.com/api/{region}/data/v1.0/subscriptions/{subscription_id}/resourceGroups/{resource_group}/providers/Microsoft.MachineLearningServices/workspaces/{workspace_name}/dataversion/getByAssetId\"\n",
    "    payload = {\n",
    "            \"value\": output_asset_id,\n",
    "        }\n",
    "    response = requests.post(url, json=payload, headers=ws._auth.get_authentication_header())\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to get asset path for asset id {asset_id} because Data API returned status code {response.status_code}. Response: {response.text}\")\n",
    "    data_uri = response.json()[\"dataVersion\"][\"dataUri\"]\n",
    "    relative_path = data_uri.split(\"/paths/\")[-1]\n",
    "\n",
    "    destination_path = os.path.join(\"../runs\",run_id)\n",
    "    if not os.path.exists(destination_path):\n",
    "        os.makedirs(destination_path)\n",
    "    \n",
    "    default_datastore.download(destination_path, prefix=relative_path +'flow_artifacts', overwrite=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promptflow/PromptFlowArtifacts/rag_flow_grid_step_3_variant_0_20240417_111404_012615/\n",
      "Downloading promptflow/PromptFlowArtifacts/rag_flow_grid_step_3_variant_0_20240417_111404_012615/flow_artifacts/000000000_000000024.jsonl\n",
      "Downloaded promptflow/PromptFlowArtifacts/rag_flow_grid_step_3_variant_0_20240417_111404_012615/flow_artifacts/000000000_000000024.jsonl, 1 files out of an estimated total of 1\n"
     ]
    }
   ],
   "source": [
    "download_artifacts(run_id, asset_name, ws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading promptflow/PromptFlowArtifacts/rag_flow_grid_step_3_variant_0_20240417_111404_012615/flow_artifacts/000000000_000000024.jsonl\n",
      "Downloaded promptflow/PromptFlowArtifacts/rag_flow_grid_step_3_variant_0_20240417_111404_012615/flow_artifacts/000000000_000000024.jsonl, 1 files out of an estimated total of 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_datastore.download('../tmp', prefix='promptflow/PromptFlowArtifacts/rag_flow_grid_step_3_variant_0_20240417_111404_012615/flow_artifacts', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_number</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>status</th>\n",
       "      <th>tags</th>\n",
       "      <th>run_id</th>\n",
       "      <th>status</th>\n",
       "      <th>error</th>\n",
       "      <th>...</th>\n",
       "      <th>message_format</th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>inputs.llm_connection</th>\n",
       "      <th>output.response</th>\n",
       "      <th>system_metrics.duration</th>\n",
       "      <th>system_metrics.prompt_tokens</th>\n",
       "      <th>system_metrics.completion_tokens</th>\n",
       "      <th>system_metrics.total_tokens</th>\n",
       "      <th>result.response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-17 15:17:02.898586</td>\n",
       "      <td>2024-04-17 15:17:04.664327</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rag_flow_grid_step_3_variant_0_20240417_111404...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>basic</td>\n",
       "      <td>What is the capital of the United States?</td>\n",
       "      <td>0</td>\n",
       "      <td>mistral-large-maas</td>\n",
       "      <td>The capital of the United States is Washington...</td>\n",
       "      <td>1.765741</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The capital of the United States is Washington...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-04-17 15:17:02.949075</td>\n",
       "      <td>2024-04-17 15:17:04.882840</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rag_flow_grid_step_3_variant_0_20240417_111404...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>basic</td>\n",
       "      <td>What is the capital of Spain?</td>\n",
       "      <td>3</td>\n",
       "      <td>mistral-large-maas</td>\n",
       "      <td>The capital of Spain is Madrid. It's known for...</td>\n",
       "      <td>1.933765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The capital of Spain is Madrid. It's known for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-17 15:17:02.966568</td>\n",
       "      <td>2024-04-17 15:17:05.270017</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rag_flow_grid_step_3_variant_0_20240417_111404...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>basic</td>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>1</td>\n",
       "      <td>mistral-large-maas</td>\n",
       "      <td>The capital of France is Paris. Known as \"The ...</td>\n",
       "      <td>2.303449</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The capital of France is Paris. Known as \"The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-04-17 15:17:02.961668</td>\n",
       "      <td>2024-04-17 15:17:05.715646</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rag_flow_grid_step_3_variant_0_20240417_111404...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>basic</td>\n",
       "      <td>What is the capital of Mexico?</td>\n",
       "      <td>2</td>\n",
       "      <td>mistral-large-maas</td>\n",
       "      <td>The capital of Mexico is Mexico City. It's one...</td>\n",
       "      <td>2.753978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The capital of Mexico is Mexico City. It's one...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   line_number                 start_time                   end_time name  \\\n",
       "0            0 2024-04-17 15:17:02.898586 2024-04-17 15:17:04.664327        \n",
       "1            3 2024-04-17 15:17:02.949075 2024-04-17 15:17:04.882840        \n",
       "2            1 2024-04-17 15:17:02.966568 2024-04-17 15:17:05.270017        \n",
       "3            2 2024-04-17 15:17:02.961668 2024-04-17 15:17:05.715646        \n",
       "\n",
       "  description     status  tags  \\\n",
       "0              Completed   NaN   \n",
       "1              Completed   NaN   \n",
       "2              Completed   NaN   \n",
       "3              Completed   NaN   \n",
       "\n",
       "                                              run_id     status error  ...  \\\n",
       "0  rag_flow_grid_step_3_variant_0_20240417_111404...  Completed  None  ...   \n",
       "1  rag_flow_grid_step_3_variant_0_20240417_111404...  Completed  None  ...   \n",
       "2  rag_flow_grid_step_3_variant_0_20240417_111404...  Completed  None  ...   \n",
       "3  rag_flow_grid_step_3_variant_0_20240417_111404...  Completed  None  ...   \n",
       "\n",
       "  message_format                            inputs.question  \\\n",
       "0          basic  What is the capital of the United States?   \n",
       "1          basic              What is the capital of Spain?   \n",
       "2          basic             What is the capital of France?   \n",
       "3          basic             What is the capital of Mexico?   \n",
       "\n",
       "  inputs.line_number inputs.llm_connection  \\\n",
       "0                  0    mistral-large-maas   \n",
       "1                  3    mistral-large-maas   \n",
       "2                  1    mistral-large-maas   \n",
       "3                  2    mistral-large-maas   \n",
       "\n",
       "                                     output.response system_metrics.duration  \\\n",
       "0  The capital of the United States is Washington...                1.765741   \n",
       "1  The capital of Spain is Madrid. It's known for...                1.933765   \n",
       "2  The capital of France is Paris. Known as \"The ...                2.303449   \n",
       "3  The capital of Mexico is Mexico City. It's one...                2.753978   \n",
       "\n",
       "  system_metrics.prompt_tokens system_metrics.completion_tokens  \\\n",
       "0                            0                                0   \n",
       "1                            0                                0   \n",
       "2                            0                                0   \n",
       "3                            0                                0   \n",
       "\n",
       "   system_metrics.total_tokens  \\\n",
       "0                            0   \n",
       "1                            0   \n",
       "2                            0   \n",
       "3                            0   \n",
       "\n",
       "                                     result.response  \n",
       "0  The capital of the United States is Washington...  \n",
       "1  The capital of Spain is Madrid. It's known for...  \n",
       "2  The capital of France is Paris. Known as \"The ...  \n",
       "3  The capital of Mexico is Mexico City. It's one...  \n",
       "\n",
       "[4 rows x 35 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "# Specify the path to your JSONL file\n",
    "jsonl_file = '/home/vhoudebine/projects/pf-models-evaluation/tmp/promptflow/PromptFlowArtifacts/rag_flow_grid_step_3_variant_0_20240417_111404_012615/flow_artifacts/000000000_000000024.jsonl'\n",
    "\n",
    "# Load the JSONL file into a pandas DataFrame\n",
    "df = pd.read_json(jsonl_file, lines=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()\n",
    "# Flatten the run_info column\n",
    "df_flattened = json_normalize(df['run_info'])\n",
    "\n",
    "# Concatenate the flattened DataFrame with the original DataFrame\n",
    "df = pd.concat([df, df_flattened], axis=1)\n",
    "\n",
    "# Drop the original run_info column\n",
    "df = df.drop('run_info', axis=1)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import json\n",
    "\n",
    "# Example JSON\n",
    "json_data = {\"line_number\": 2, \"run_info\": {\"run_id\": \"rag_flow_grid_step_3_variant_0_20240417_111404_012615_2\", \"status\": \"Completed\", \"error\": None, \"inputs\": {\"question\": \"What is the capital of Mexico?\", \"line_number\": 2, \"llm_connection\": \"mistral-large-maas\"}, \"output\": {\"response\": \"The capital of Mexico is Mexico City. It's one of the largest and most populous cities in the world, known for its rich history, vibrant culture, and unique cuisine. Mexico City is also famous for its historic center, known as Zocalo, which is a UNESCO World Heritage Site and houses ancient Aztec temples and Spanish colonial-era buildings.\"}, \"metrics\": None, \"request\": None, \"parent_run_id\": \"rag_flow_grid_step_3_variant_0_20240417_111404_012615\", \"root_run_id\": \"rag_flow_grid_step_3_variant_0_20240417_111404_012615\", \"source_run_id\": None, \"flow_id\": \"default_flow_id\", \"start_time\": \"2024-04-17T15:17:02.961668Z\", \"end_time\": \"2024-04-17T15:17:05.715646Z\", \"index\": 2, \"api_calls\": [{\"name\": \"flow\", \"node_name\": \"flow\", \"type\": \"Flow\", \"start_time\": 1713367022.961668, \"end_time\": 1713367025.715646, \"children\": [{\"name\": \"my_python_tool\", \"type\": \"Function\", \"inputs\": {\"conn\": \"mistral-large-maas\", \"message\": \"What is the capital of Mexico?\"}, \"output\": \"The capital of Mexico is Mexico City. It's one of the largest and most populous cities in the world, known for its rich history, vibrant culture, and unique cuisine. Mexico City is also famous for its historic center, known as Zocalo, which is a UNESCO World Heritage Site and houses ancient Aztec temples and Spanish colonial-era buildings.\", \"start_time\": 1713367022.974426, \"end_time\": 1713367025.711773, \"error\": None, \"children\": [], \"node_name\": \"llm_node\", \"parent_id\": \"\", \"id\": \"6ad0dffb-38a2-4d5e-96ee-e68d3c5bc5bb\", \"function\": \"my_python_tool\", \"system_metrics\": {}}], \"system_metrics\": {\"duration\": 2.753978, \"prompt_tokens\": 0, \"completion_tokens\": 0, \"total_tokens\": 0}, \"inputs\": {\"question\": \"What is the capital of Mexico?\", \"line_number\": 2, \"llm_connection\": \"mistral-large-maas\"}, \"output\": {\"response\": \"The capital of Mexico is Mexico City. It's one of the largest and most populous cities in the world, known for its rich history, vibrant culture, and unique cuisine. Mexico City is also famous for its historic center, known as Zocalo, which is a UNESCO World Heritage Site and houses ancient Aztec temples and Spanish colonial-era buildings.\"}, \"error\": None}], \"name\": \"\", \"description\": \"\", \"tags\": None, \"system_metrics\": {\"duration\": 2.753978, \"prompt_tokens\": 0, \"completion_tokens\": 0, \"total_tokens\": 0}, \"result\": {\"response\": \"The capital of Mexico is Mexico City. It's one of the largest and most populous cities in the world, known for its rich history, vibrant culture, and unique cuisine. Mexico City is also famous for its historic center, known as Zocalo, which is a UNESCO World Heritage Site and houses ancient Aztec temples and Spanish colonial-era buildings.\"}, \"upload_metrics\": False, \"otel_trace_id\": \"00000000000000000000000000000000\", \"message_format\": \"basic\"}, \"start_time\": \"2024-04-17T15:17:02.961668\", \"end_time\": \"2024-04-17T15:17:05.715646\", \"name\": \"\", \"description\": \"\", \"status\": \"Completed\", \"tags\": None}\n",
    "\n",
    "api_calls = json_data.get('run_info').get('api_calls')\n",
    "\n",
    "nodes = [call.get('children')[0] for call in api_calls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'my_python_tool',\n",
       "  'type': 'Function',\n",
       "  'inputs': {'conn': 'mistral-large-maas',\n",
       "   'message': 'What is the capital of Mexico?'},\n",
       "  'output': \"The capital of Mexico is Mexico City. It's one of the largest and most populous cities in the world, known for its rich history, vibrant culture, and unique cuisine. Mexico City is also famous for its historic center, known as Zocalo, which is a UNESCO World Heritage Site and houses ancient Aztec temples and Spanish colonial-era buildings.\",\n",
       "  'start_time': 1713367022.974426,\n",
       "  'end_time': 1713367025.711773,\n",
       "  'error': None,\n",
       "  'children': [],\n",
       "  'node_name': 'llm_node',\n",
       "  'parent_id': '',\n",
       "  'id': '6ad0dffb-38a2-4d5e-96ee-e68d3c5bc5bb',\n",
       "  'function': 'my_python_tool',\n",
       "  'system_metrics': {}}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>inputs</th>\n",
       "      <th>output</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>error</th>\n",
       "      <th>children</th>\n",
       "      <th>node_name</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>id</th>\n",
       "      <th>function</th>\n",
       "      <th>system_metrics</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my_python_tool</td>\n",
       "      <td>Function</td>\n",
       "      <td>{'conn': 'mistral-large-maas', 'message': 'Wha...</td>\n",
       "      <td>The capital of Mexico is Mexico City. It's one...</td>\n",
       "      <td>1.713367e+09</td>\n",
       "      <td>1.713367e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>llm_node</td>\n",
       "      <td></td>\n",
       "      <td>6ad0dffb-38a2-4d5e-96ee-e68d3c5bc5bb</td>\n",
       "      <td>my_python_tool</td>\n",
       "      <td>{}</td>\n",
       "      <td>3.000000e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name      type  \\\n",
       "0  my_python_tool  Function   \n",
       "\n",
       "                                              inputs  \\\n",
       "0  {'conn': 'mistral-large-maas', 'message': 'Wha...   \n",
       "\n",
       "                                              output    start_time  \\\n",
       "0  The capital of Mexico is Mexico City. It's one...  1.713367e+09   \n",
       "\n",
       "       end_time error children node_name parent_id  \\\n",
       "0  1.713367e+09  None       []  llm_node             \n",
       "\n",
       "                                     id        function system_metrics  \\\n",
       "0  6ad0dffb-38a2-4d5e-96ee-e68d3c5bc5bb  my_python_tool             {}   \n",
       "\n",
       "   execution_time  \n",
       "0    3.000000e-09  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'line_number': 2,\n",
       " 'run_info': {'run_id': 'rag_flow_grid_step_3_variant_0_20240417_111404_012615_2',\n",
       "  'status': 'Completed',\n",
       "  'error': None,\n",
       "  'inputs': {'question': 'What is the capital of Mexico?',\n",
       "   'line_number': 2,\n",
       "   'llm_connection': 'mistral-large-maas'},\n",
       "  'output': {'response': \"The capital of Mexico is Mexico City. It's one of the largest and most populous cities in the world, known for its rich history, vibrant culture, and unique cuisine. Mexico City is also famous for its historic center, known as Zocalo, which is a UNESCO World Heritage Site and houses ancient Aztec temples and Spanish colonial-era buildings.\"},\n",
       "  'metrics': None,\n",
       "  'request': None,\n",
       "  'parent_run_id': 'rag_flow_grid_step_3_variant_0_20240417_111404_012615',\n",
       "  'root_run_id': 'rag_flow_grid_step_3_variant_0_20240417_111404_012615',\n",
       "  'source_run_id': None,\n",
       "  'flow_id': 'default_flow_id',\n",
       "  'start_time': '2024-04-17T15:17:02.961668Z',\n",
       "  'end_time': '2024-04-17T15:17:05.715646Z',\n",
       "  'index': 2,\n",
       "  'api_calls': [{'name': 'flow',\n",
       "    'node_name': 'flow',\n",
       "    'type': 'Flow',\n",
       "    'start_time': 1713367022.961668,\n",
       "    'end_time': 1713367025.715646,\n",
       "    'children': [{'name': 'my_python_tool',\n",
       "      'type': 'Function',\n",
       "      'inputs': {'conn': 'mistral-large-maas',\n",
       "       'message': 'What is the capital of Mexico?'},\n",
       "      'output': \"The capital of Mexico is Mexico City. It's one of the largest and most populous cities in the world, known for its rich history, vibrant culture, and unique cuisine. Mexico City is also famous for its historic center, known as Zocalo, which is a UNESCO World Heritage Site and houses ancient Aztec temples and Spanish colonial-era buildings.\",\n",
       "      'start_time': 1713367022.974426,\n",
       "      'end_time': 1713367025.711773,\n",
       "      'error': None,\n",
       "      'children': [],\n",
       "      'node_name': 'llm_node',\n",
       "      'parent_id': '',\n",
       "      'id': '6ad0dffb-38a2-4d5e-96ee-e68d3c5bc5bb',\n",
       "      'function': 'my_python_tool',\n",
       "      'system_metrics': {}}],\n",
       "    'system_metrics': {'duration': 2.753978,\n",
       "     'prompt_tokens': 0,\n",
       "     'completion_tokens': 0,\n",
       "     'total_tokens': 0},\n",
       "    'inputs': {'question': 'What is the capital of Mexico?',\n",
       "     'line_number': 2,\n",
       "     'llm_connection': 'mistral-large-maas'},\n",
       "    'output': {'response': \"The capital of Mexico is Mexico City. It's one of the largest and most populous cities in the world, known for its rich history, vibrant culture, and unique cuisine. Mexico City is also famous for its historic center, known as Zocalo, which is a UNESCO World Heritage Site and houses ancient Aztec temples and Spanish colonial-era buildings.\"},\n",
       "    'error': None}],\n",
       "  'name': '',\n",
       "  'description': '',\n",
       "  'tags': None,\n",
       "  'system_metrics': {'duration': 2.753978,\n",
       "   'prompt_tokens': 0,\n",
       "   'completion_tokens': 0,\n",
       "   'total_tokens': 0},\n",
       "  'result': {'response': \"The capital of Mexico is Mexico City. It's one of the largest and most populous cities in the world, known for its rich history, vibrant culture, and unique cuisine. Mexico City is also famous for its historic center, known as Zocalo, which is a UNESCO World Heritage Site and houses ancient Aztec temples and Spanish colonial-era buildings.\"},\n",
       "  'upload_metrics': False,\n",
       "  'otel_trace_id': '00000000000000000000000000000000',\n",
       "  'message_format': 'basic'},\n",
       " 'start_time': '2024-04-17T15:17:02.961668',\n",
       " 'end_time': '2024-04-17T15:17:05.715646',\n",
       " 'name': '',\n",
       " 'description': '',\n",
       " 'status': 'Completed',\n",
       " 'tags': None}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flowgrid import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'flowgrid.utils' has no attribute 'download_artifacts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_artifacts\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrag_flow_grid_step_1_variant_0_20240419_145900_268384\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      2\u001b[0m                                  default_datastore, \n\u001b[1;32m      3\u001b[0m                                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdebug_info\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      4\u001b[0m                                  aml_ws,\n\u001b[1;32m      5\u001b[0m                                  subscription_id,\n\u001b[1;32m      6\u001b[0m                                  resource_group,\n\u001b[1;32m      7\u001b[0m                                  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./run_outputs/test/run_test\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'flowgrid.utils' has no attribute 'download_artifacts'"
     ]
    }
   ],
   "source": [
    "utils.download_artifacts(\"rag_flow_grid_step_1_variant_0_20240419_145900_268384\", \n",
    "                                 default_datastore, \n",
    "                                 \"debug_info\", \n",
    "                                 aml_ws,\n",
    "                                 subscription_id,\n",
    "                                 resource_group,\n",
    "                                 f\"./run_outputs/test/run_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'llm': {'model': {'name': 'gpt2', 'size': 'medium'},\n",
       "   'connection': 'mistral-large-maas'}}]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.duplicate_dict({'llm': {'model': {'name': 'gpt2', 'size': 'medium'}, 'connection': 'mistral-large-maas'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../flowgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/vhoudebine/projects/pf-models-evaluation/run_outputs/run_20240419153429/run_rag_flow_grid_step_0_variant_0_20240419_153432_008863\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import glob\n",
    "folder_path = '/home/vhoudebine/projects/pf-models-evaluation/run_outputs/run_20240419153429'\n",
    "\n",
    "#list all jsonl files\n",
    "jsonl_files = glob.glob(folder_path + '/**/*.jsonl', recursive=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/vhoudebine/projects/pf-models-evaluation/run_outputs/run_20240419153429/run_rag_flow_grid_step_0_variant_0_20240419_153432_008863/rag_flow_grid_step_0_variant_0_20240419_153432_008863/promptflow/PromptFlowArtifacts/rag_flow_grid_step_0_variant_0_20240419_153432_008863/flow_artifacts/000000000_000000024.jsonl',\n",
       " '/home/vhoudebine/projects/pf-models-evaluation/run_outputs/run_20240419153429/run_rag_flow_grid_step_3_variant_0_20240419_153432_011985/rag_flow_grid_step_3_variant_0_20240419_153432_011985/promptflow/PromptFlowArtifacts/rag_flow_grid_step_3_variant_0_20240419_153432_011985/flow_artifacts/000000000_000000024.jsonl',\n",
       " '/home/vhoudebine/projects/pf-models-evaluation/run_outputs/run_20240419153429/run_rag_flow_grid_step_2_variant_0_20240419_153432_011481/rag_flow_grid_step_2_variant_0_20240419_153432_011481/promptflow/PromptFlowArtifacts/rag_flow_grid_step_2_variant_0_20240419_153432_011481/flow_artifacts/000000000_000000024.jsonl',\n",
       " '/home/vhoudebine/projects/pf-models-evaluation/run_outputs/run_20240419153429/run_rag_flow_grid_step_1_variant_0_20240419_153432_009344/rag_flow_grid_step_1_variant_0_20240419_153432_009344/promptflow/PromptFlowArtifacts/rag_flow_grid_step_1_variant_0_20240419_153432_009344/flow_artifacts/000000000_000000024.jsonl']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonl_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8)\n",
      "(4, 8)\n",
      "(4, 8)\n",
      "(4, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "runs_df = pd.DataFrame()\n",
    "# Specify the path to your JSONL file\n",
    "for file_path in jsonl_files:\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "    print(df.shape)\n",
    "    df_flattened = json_normalize(df['run_info'])\n",
    "\n",
    "    # Concatenate the flattened DataFrame with the original DataFrame\n",
    "    df = pd.concat([df, df_flattened], axis=1)\n",
    "    df['run_id'] = file_path.split('/')[-3]\n",
    "\n",
    "    # Drop the original run_info column\n",
    "    df = df.drop('run_info', axis=1)\n",
    "\n",
    "    df.head()\n",
    "\n",
    "    runs_df = pd.concat([runs_df, df], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['line_number', 'start_time', 'end_time', 'name', 'description',\n",
       "       'status', 'tags', 'run_id', 'status', 'error', 'metrics', 'request',\n",
       "       'parent_run_id', 'root_run_id', 'source_run_id', 'flow_id',\n",
       "       'start_time', 'end_time', 'index', 'api_calls', 'name', 'description',\n",
       "       'tags', 'upload_metrics', 'otel_trace_id', 'message_format',\n",
       "       'inputs.question', 'inputs.line_number', 'inputs.llm_connection',\n",
       "       'output.response', 'system_metrics.duration',\n",
       "       'system_metrics.prompt_tokens', 'system_metrics.completion_tokens',\n",
       "       'system_metrics.total_tokens', 'result.response'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [{'name': 'flow', 'node_name': 'flow', 'type':...\n",
       "1    [{'name': 'flow', 'node_name': 'flow', 'type':...\n",
       "2    [{'name': 'flow', 'node_name': 'flow', 'type':...\n",
       "3    [{'name': 'flow', 'node_name': 'flow', 'type':...\n",
       "0    [{'name': 'flow', 'node_name': 'flow', 'type':...\n",
       "1    [{'name': 'flow', 'node_name': 'flow', 'type':...\n",
       "2    [{'name': 'flow', 'node_name': 'flow', 'type':...\n",
       "3    [{'name': 'flow', 'node_name': 'flow', 'type':...\n",
       "0    [{'name': 'flow', 'node_name': 'flow', 'type':...\n",
       "1    [{'name': 'flow', 'node_name': 'flow', 'type':...\n",
       "2    [{'name': 'flow', 'node_name': 'flow', 'type':...\n",
       "3    [{'name': 'flow', 'node_name': 'flow', 'type':...\n",
       "0    [{'name': 'flow', 'node_name': 'flow', 'type':...\n",
       "1    [{'name': 'flow', 'node_name': 'flow', 'type':...\n",
       "2    [{'name': 'flow', 'node_name': 'flow', 'type':...\n",
       "3    [{'name': 'flow', 'node_name': 'flow', 'type':...\n",
       "Name: api_calls, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_df['api_calls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'azureml.promptflow.runtime_name': 'automatic',\n",
       " 'azureml.promptflow.inputs_mapping': '{\"question\":\"${data.question}\"}',\n",
       " 'azureml.promptflow.disable_trace': 'false',\n",
       " 'azureml.promptflow.session_id': '77befb68e3670e449c94c2019b3ffe069ce86d08ba6a0cd2',\n",
       " 'azureml.promptflow.definition_file_name': 'flow.dag.yaml',\n",
       " 'azureml.promptflow.flow_lineage_id': 'e24a37f34d10f789a58dd9cda30c9c64e5885ebb5a72434a6a32aa67089d78f1',\n",
       " 'azureml.promptflow.flow_definition_datastore_name': 'workspaceblobstore',\n",
       " 'azureml.promptflow.flow_definition_blob_path': 'LocalUpload/2cc2c00ae7b79262f06b81cf6923abba/rag_flow_grid_step_0/flow.dag.yaml',\n",
       " '_azureml.evaluation_run': 'promptflow.BatchRun',\n",
       " 'azureml.promptflow.snapshot_id': '750686e5-4d69-4aae-82f3-b30491bbc480',\n",
       " 'azureml.promptflow.runtime_version': '20240411.v4',\n",
       " 'azureml.promptflow.total_tokens': '132',\n",
       " '_azureml.evaluate_artifacts': '[{\"path\": \"instance_results.jsonl\", \"type\": \"table\"}]'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.runs.get('rag_flow_grid_step_0_variant_0_20240419_153432_008863').properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_and_execute(\n",
    "    subscription_id,\n",
    "    build_id, stage,\n",
    "    run_id,\n",
    "    data_purpose,\n",
    "    flow_to_execute\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the evaluation loop by executing evaluation flows.\n",
    "\n",
    "    reads latest evaluation data assets\n",
    "    executes evaluation flow against each provided bulk-run\n",
    "    executes the flow creating a new evaluation job\n",
    "    saves the results in both csv and html format\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    main_config = open(f\"{flow_to_execute}/llmops_config.json\")\n",
    "    model_config = json.load(main_config)\n",
    "\n",
    "    for obj in model_config[\"envs\"]:\n",
    "        if obj.get(\"ENV_NAME\") == stage:\n",
    "            config = obj\n",
    "            break\n",
    "\n",
    "    resource_group_name = config[\"RESOURCE_GROUP_NAME\"]\n",
    "    workspace_name = config[\"WORKSPACE_NAME\"]\n",
    "    data_mapping_config = f\"{flow_to_execute}/configs/mapping_config.json\"\n",
    "    standard_flow_path = config[\"STANDARD_FLOW_PATH\"]\n",
    "    data_config_path = f\"{flow_to_execute}/configs/data_config.json\"\n",
    "\n",
    "    runtime = config[\"RUNTIME_NAME\"]\n",
    "    eval_flow_path = config[\"EVALUATION_FLOW_PATH\"]\n",
    "    experiment_name = f\"{flow_to_execute}_{stage}\"\n",
    "\n",
    "    eval_flows = eval_flow_path.split(\",\")\n",
    "\n",
    "    pf = PFClient(\n",
    "        DefaultAzureCredential(),\n",
    "        subscription_id,\n",
    "        resource_group_name,\n",
    "        workspace_name\n",
    "    )\n",
    "\n",
    "    standard_flow = f\"{flow_to_execute}/{standard_flow_path}\"\n",
    "    dataset_name = []\n",
    "    config_file = open(data_config_path)\n",
    "    data_config = json.load(config_file)\n",
    "    for elem in data_config[\"datasets\"]:\n",
    "        if \"DATA_PURPOSE\" in elem and \"ENV_NAME\" in elem:\n",
    "            if (stage == elem[\"ENV_NAME\"] and\n",
    "                    data_purpose == elem[\"DATA_PURPOSE\"]):\n",
    "\n",
    "                data_name = elem[\"DATASET_NAME\"]\n",
    "                related_data = elem[\"RELATED_EXP_DATASET\"]\n",
    "                data = pf.ml_client.data.get(name=data_name, label=\"latest\")\n",
    "                data_id = f\"azureml:{data.name}:{data.version}\"\n",
    "                dataset_name.append(\n",
    "                    {\n",
    "                        \"data_id\": data_id,\n",
    "                        \"ref_data\": related_data\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    standard_flow_file = f\"{standard_flow}/flow.dag.yaml\"\n",
    "\n",
    "    with open(standard_flow_file, \"r\") as yaml_file:\n",
    "        yaml_data = yaml.safe_load(yaml_file)\n",
    "\n",
    "    default_variants = []\n",
    "    for node_name, node_data in yaml_data.get(\"node_variants\", {}).items():\n",
    "        node_variant_mapping = {}\n",
    "        default_variant = node_data[\"default_variant_id\"]\n",
    "        node_variant_mapping[node_name] = default_variant\n",
    "        default_variants.append(node_variant_mapping)\n",
    "\n",
    "    mapping_file = open(data_mapping_config)\n",
    "    mapping_config = json.load(mapping_file)\n",
    "    eval_config_node = mapping_config[\"evaluation\"]\n",
    "\n",
    "    all_eval_df = []\n",
    "    all_eval_metrics = []\n",
    "\n",
    "    run_ids = ast.literal_eval(run_id)\n",
    "\n",
    "    for flow in eval_flows:\n",
    "        flow = f\"{flow_to_execute}/{flow.strip()}\"\n",
    "        dataframes = []\n",
    "        metrics = []\n",
    "\n",
    "        flow_name = (flow.split(\"/\")[-1]).strip()\n",
    "        mapping_node = eval_config_node[flow_name]\n",
    "        for flow_run in run_ids:\n",
    "            my_run = pf.runs.get(flow_run)\n",
    "            run_data_id = my_run.data.replace(\"azureml:\", \"\")\n",
    "            run_data_id = run_data_id.split(\":\")[0]\n",
    "            for data_item in dataset_name:\n",
    "                data_n = data_item[\"data_id\"]\n",
    "                ref_data = data_item[\"ref_data\"]\n",
    "                if ref_data == run_data_id:\n",
    "                    data_id = data_n\n",
    "                    break\n",
    "\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "            eval_run = Run(\n",
    "                flow=flow.strip(),\n",
    "                data=data_id,\n",
    "                run=my_run,\n",
    "                column_mapping=mapping_node,\n",
    "                runtime=runtime,\n",
    "                # un-comment the resources parameter assignment\n",
    "                # and update the size of the compute and also\n",
    "                # comment the runtime parameter assignment to\n",
    "                # enable automatic runtime.\n",
    "                # Reference: COMPUTE_RUNTIME\n",
    "                # resources={\"instance_type\": \"Standard_E4ds_v4\"},\n",
    "                name=f\"{experiment_name}_eval_{timestamp}\",\n",
    "                display_name=f\"{experiment_name}_eval_{timestamp}\",\n",
    "                tags={\"build_id\": build_id},\n",
    "            )\n",
    "            eval_run._experiment_name = experiment_name\n",
    "            eval_job = pf.runs.create_or_update(eval_run, stream=True)\n",
    "            df_result = None\n",
    "\n",
    "            time.sleep(15)\n",
    "\n",
    "            if eval_job.status == \"Completed\" or eval_job.status == \"Finished\":\n",
    "                logger.info(eval_job.status)\n",
    "                df_result = pf.get_details(eval_job)\n",
    "                metric_variant = pf.get_metrics(eval_job)\n",
    "\n",
    "                if (\n",
    "                    my_run.properties.get(\n",
    "                        \"azureml.promptflow.node_variant\",\n",
    "                        None) is not None\n",
    "                ):\n",
    "                    variant_id = \\\n",
    "                        my_run.properties[\"azureml.promptflow.node_variant\"]\n",
    "                    start_index = variant_id.find(\"{\") + 1\n",
    "                    end_index = variant_id.find(\"}\")\n",
    "                    variant_value = \\\n",
    "                        variant_id[start_index:end_index].split(\".\")\n",
    "\n",
    "                    df_result[variant_value[0]] = variant_value[1]\n",
    "                    metric_variant[variant_value[0]] = variant_value[1]\n",
    "                    df_result[\"dataset\"] = data_id\n",
    "                    metric_variant[\"dataset\"] = data_id\n",
    "\n",
    "                    for var in default_variants:\n",
    "                        for key in var.keys():\n",
    "                            if key == variant_value[0]:\n",
    "                                pass\n",
    "                            else:\n",
    "                                df_result[key] = var[key]\n",
    "                                metric_variant[key] = var[key]\n",
    "\n",
    "                dataframes.append(df_result)\n",
    "                metrics.append(metric_variant)\n",
    "\n",
    "                logger.info(json.dumps(metrics, indent=4))\n",
    "                logger.info(df_result.head(10))\n",
    "\n",
    "            else:\n",
    "                raise Exception(\"Sorry, exiting job with failure..\")\n",
    "\n",
    "        if not os.path.exists(\"./reports\"):\n",
    "            os.makedirs(\"./reports\")\n",
    "\n",
    "        combined_results_df = pd.concat(dataframes, ignore_index=True)\n",
    "        combined_metrics_df = pd.DataFrame(metrics)\n",
    "        combined_results_df[\"flow_name\"] = flow_name\n",
    "        combined_metrics_df[\"flow_name\"] = flow_name\n",
    "        combined_results_df[\"exp_run\"] = flow_run\n",
    "        combined_metrics_df[\"exp_run\"] = flow_run\n",
    "\n",
    "        combined_results_df.to_csv(f\"./reports/{run_data_id}_result.csv\")\n",
    "        combined_metrics_df.to_csv(f\"./reports/{run_data_id}_metrics.csv\")\n",
    "\n",
    "        styled_df = combined_results_df.to_html(index=False)\n",
    "\n",
    "        with open(f\"reports/{run_data_id}_result.html\", \"w\") as c_results:\n",
    "            c_results.write(styled_df)\n",
    "\n",
    "        html_table_metrics = combined_metrics_df.to_html(index=False)\n",
    "        with open(f\"reports/{run_data_id}_metrics.html\", \"w\") as c_metrics:\n",
    "            c_metrics.write(html_table_metrics)\n",
    "\n",
    "        all_eval_df.append(combined_results_df)\n",
    "        all_eval_metrics.append(combined_metrics_df)\n",
    "\n",
    "    final_results_df = pd.concat(all_eval_df, ignore_index=True)\n",
    "    final_metrics_df = pd.concat(all_eval_metrics, ignore_index=True)\n",
    "    final_results_df[\"stage\"] = stage\n",
    "    final_results_df[\"experiment_name\"] = experiment_name\n",
    "    final_results_df[\"build\"] = build_id\n",
    "\n",
    "    final_results_df.to_csv(f\"./reports/{experiment_name}_result.csv\")\n",
    "    final_metrics_df.to_csv(f\"./reports/{experiment_name}_metrics.csv\")\n",
    "\n",
    "    styled_df = final_results_df.to_html(index=False)\n",
    "    with open(f\"reports/{experiment_name}_result.html\", \"w\") as f_results:\n",
    "        f_results.write(styled_df)\n",
    "\n",
    "    html_table_metrics = final_metrics_df.to_html(index=False)\n",
    "    with open(f\"reports/{experiment_name}_metrics.html\", \"w\") as f_metrics:\n",
    "        f_metrics.write(html_table_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'from promptflow import tool' is deprecated and will be removed in the future. Use 'from promptflow.core import tool' instead.\n",
      "WARNING:root:'from promptflow import log_metric' is deprecated and will be removed in the future. Use 'from promptflow.core import log_metric' instead.\n",
      "[2024-04-22 12:26:39,661][promptflow][WARNING] - You're using automatic runtime, if it's first time you're using it, it may take a while to build runtime and you may see 'NotStarted' status for a while. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portal url: https://ml.azure.com/runs/rag_flow_grid_step_4_eval_eval_20240422_122637?wsid=/subscriptions/6c065ea7-65cd-4a34-8e2a-3e21ad4a8e9f/resourcegroups/vince-rg/providers/Microsoft.MachineLearningServices/workspaces/vince-dev\n",
      "2024-04-22 16:26:47 +0000     174 promptflow-runtime INFO     [rag_flow_grid_step_4_eval_eval_20240422_122637] Receiving v2 bulk run request 9cb3bddf-8729-4fd9-8996-ac85ed3d1fe7: {\"flow_id\": \"rag_flow_grid_step_4_eval_eval_20240422_122637\", \"flow_run_id\": \"rag_flow_grid_step_4_eval_eval_20240422_122637\", \"flow_source\": {\"flow_source_type\": 1, \"flow_source_info\": {\"snapshot_id\": \"3caa1cc8-7b6e-4e1b-aa90-79c49a46e15a\"}, \"flow_dag_file\": \"flow.dag.yaml\"}, \"log_path\": \"https://vincedev4106797923.blob.core.windows.net/azureml/ExperimentRun/dcid.rag_flow_grid_step_4_eval_eval_20240422_122637/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=**data_scrubbed**&skoid=4af85c54-3f14-4b6a-a706-a4a6e971c4e7&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2024-04-22T13%3A05%3A45Z&ske=2024-04-23T21%3A15%3A45Z&sks=b&skv=2019-07-07&st=2024-04-22T16%3A16%3A47Z&se=2024-04-23T00%3A26%3A47Z&sp=rcw\", \"app_insights_instrumentation_key\": \"InstrumentationKey=**data_scrubbed**;IngestionEndpoint=https://eastus-6.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/\", \"flow_name\": \"rag_flow_grid_step_4_eval_eval_20240422_122637\", \"batch_timeout_sec\": 36000, \"data_inputs\": {\"data\": \"azureml://datastores/workspaceblobstore/paths/LocalUpload/8381842cdd004ce41a740844a5146deb/data.jsonl\", \"run.outputs\": \"azureml:/subscriptions/6c065ea7-65cd-4a34-8e2a-3e21ad4a8e9f/resourceGroups/vince-rg/providers/Microsoft.MachineLearningServices/workspaces/vince-dev/data/azureml_rag_flow_grid_step_4_variant_0_20240422_112227_503149_output_data_flow_outputs/versions/1\"}, \"inputs_mapping\": {\"answer\": \"${run.outputs.response}\", \"ground_truth\": \"${data.ground_truth}\"}, \"azure_storage_setting\": {\"azure_storage_mode\": 1, \"storage_account_name\": \"vincedev4106797923\", \"blob_container_name\": \"azureml-blobstore-6184be4d-8f14-4f56-b031-56a6ec3813fc\", \"flow_artifacts_root_path\": \"promptflow/PromptFlowArtifacts/rag_flow_grid_step_4_eval_eval_20240422_122637\", \"blob_container_sas_token\": \"?sv=2019-07-07&sr=c&sig=**data_scrubbed**&skoid=4af85c54-3f14-4b6a-a706-a4a6e971c4e7&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2024-04-22T16%3A26%3A47Z&ske=2024-04-29T16%3A26%3A47Z&sks=b&skv=2019-07-07&se=2024-04-29T16%3A26%3A47Z&sp=racwl\", \"output_datastore_name\": \"workspaceblobstore\"}, \"variant_run_id\": \"rag_flow_grid_step_4_variant_0_20240422_112227_503149\"}\n",
      "2024-04-22 16:26:47 +0000     174 promptflow-runtime INFO     Runtime version: 20240411.v4. PromptFlow version: 1.8.0rc3\n",
      "2024-04-22 16:26:47 +0000     174 promptflow-runtime INFO     Updating rag_flow_grid_step_4_eval_eval_20240422_122637 to Status.Preparing...\n",
      "2024-04-22 16:26:47 +0000     174 promptflow-runtime INFO     Downloading snapshot to /mnt/host/service/app/36945/requests/rag_flow_grid_step_4_eval_eval_20240422_122637\n",
      "2024-04-22 16:26:47 +0000     174 promptflow-runtime INFO     Get snapshot sas url for 3caa1cc8-7b6e-4e1b-aa90-79c49a46e15a.\n",
      "2024-04-22 16:26:48 +0000     174 promptflow-runtime INFO     Snapshot 3caa1cc8-7b6e-4e1b-aa90-79c49a46e15a contains 37 files.\n",
      "2024-04-22 16:26:49 +0000     174 promptflow-runtime INFO     Download snapshot 3caa1cc8-7b6e-4e1b-aa90-79c49a46e15a completed.\n",
      "2024-04-22 16:26:49 +0000     174 promptflow-runtime INFO     Successfully download snapshot to /mnt/host/service/app/36945/requests/rag_flow_grid_step_4_eval_eval_20240422_122637\n",
      "2024-04-22 16:26:49 +0000     174 promptflow-runtime INFO     About to execute a python flow.\n",
      "2024-04-22 16:26:49 +0000     174 promptflow-runtime INFO     Use spawn method to start child process.\n",
      "2024-04-22 16:26:49 +0000     174 promptflow-runtime INFO     Starting to check process 571 status for run rag_flow_grid_step_4_eval_eval_20240422_122637\n",
      "2024-04-22 16:26:49 +0000     174 promptflow-runtime INFO     Start checking run status for run rag_flow_grid_step_4_eval_eval_20240422_122637\n",
      "2024-04-22 16:26:55 +0000     571 promptflow-runtime INFO     [174--571] Start processing flowV2......\n",
      "2024-04-22 16:26:55 +0000     571 promptflow-runtime INFO     Runtime version: 20240411.v4. PromptFlow version: 1.8.0rc3\n",
      "2024-04-22 16:26:55 +0000     571 promptflow-runtime INFO     Setting mlflow tracking uri...\n",
      "2024-04-22 16:26:55 +0000     571 promptflow-runtime INFO     Validating 'AzureML Data Scientist' user authentication...\n",
      "2024-04-22 16:26:55 +0000     571 promptflow-runtime INFO     Successfully validated 'AzureML Data Scientist' user authentication.\n",
      "2024-04-22 16:26:55 +0000     571 promptflow-runtime INFO     Using AzureMLRunStorageV2\n",
      "2024-04-22 16:26:55 +0000     571 promptflow-runtime INFO     Setting mlflow tracking uri to 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/6c065ea7-65cd-4a34-8e2a-3e21ad4a8e9f/resourceGroups/vince-rg/providers/Microsoft.MachineLearningServices/workspaces/vince-dev'\n",
      "2024-04-22 16:26:55 +0000     571 promptflow-runtime INFO     Setting mlflow tracking uri to 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/6c065ea7-65cd-4a34-8e2a-3e21ad4a8e9f/resourceGroups/vince-rg/providers/Microsoft.MachineLearningServices/workspaces/vince-dev'\n",
      "2024-04-22 16:26:55 +0000     571 promptflow-runtime INFO     Creating unregistered output Asset for Run rag_flow_grid_step_4_eval_eval_20240422_122637...\n",
      "2024-04-22 16:26:56 +0000     571 promptflow-runtime INFO     Created debug_info Asset: azureml://locations/eastus/workspaces/6184be4d-8f14-4f56-b031-56a6ec3813fc/data/azureml_rag_flow_grid_step_4_eval_eval_20240422_122637_output_data_debug_info/versions/1\n",
      "2024-04-22 16:26:56 +0000     571 promptflow-runtime INFO     Creating unregistered output Asset for Run rag_flow_grid_step_4_eval_eval_20240422_122637...\n",
      "2024-04-22 16:26:56 +0000     571 promptflow-runtime INFO     Created flow_outputs output Asset: azureml://locations/eastus/workspaces/6184be4d-8f14-4f56-b031-56a6ec3813fc/data/azureml_rag_flow_grid_step_4_eval_eval_20240422_122637_output_data_flow_outputs/versions/1\n",
      "2024-04-22 16:26:56 +0000     571 promptflow-runtime INFO     Patching rag_flow_grid_step_4_eval_eval_20240422_122637...\n",
      "2024-04-22 16:26:57 +0000     571 promptflow-runtime INFO     Resolve data from url finished in 0.8423121480000191 seconds\n",
      "2024-04-22 16:26:58 +0000     571 promptflow-runtime INFO     Resolve data from url finished in 1.0228011439999136 seconds\n",
      "2024-04-22 16:26:58 +0000     571 promptflow-runtime INFO     Starting the aml run 'rag_flow_grid_step_4_eval_eval_20240422_122637'...\n",
      "2024-04-22 16:26:58 +0000     571 execution.bulk     INFO     The timeout for the batch run is 36000 seconds.\n",
      "2024-04-22 16:26:58 +0000     571 execution.bulk     INFO     Set process count to 4 by taking the minimum value among the factors of {'default_worker_count': 4, 'row_count': 4}.\n",
      "2024-04-22 16:27:04 +0000     571 execution.bulk     INFO     Process name(ForkProcess-4:2:2)-Process id(679)-Line number(0) start execution.\n",
      "2024-04-22 16:27:04 +0000     571 execution.bulk     INFO     Process name(ForkProcess-4:2:4)-Process id(687)-Line number(3) start execution.\n",
      "2024-04-22 16:27:04 +0000     571 execution.bulk     INFO     Process name(ForkProcess-4:2:1)-Process id(672)-Line number(1) start execution.\n",
      "2024-04-22 16:27:04 +0000     571 execution.bulk     INFO     Process name(ForkProcess-4:2:3)-Process id(682)-Line number(2) start execution.\n",
      "2024-04-22 16:27:04 +0000     571 execution.bulk     INFO     Process name(ForkProcess-4:2:3)-Process id(682)-Line number(2) completed.\n",
      "2024-04-22 16:27:04 +0000     571 execution.bulk     INFO     Process name(ForkProcess-4:2:2)-Process id(679)-Line number(0) completed.\n",
      "2024-04-22 16:27:04 +0000     571 execution.bulk     INFO     Process name(ForkProcess-4:2:1)-Process id(672)-Line number(1) completed.\n",
      "2024-04-22 16:27:04 +0000     571 execution.bulk     INFO     Process name(ForkProcess-4:2:4)-Process id(687)-Line number(3) completed.\n",
      "2024-04-22 16:27:04 +0000     571 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2024-04-22 16:27:05 +0000     571 execution.bulk     INFO     Average execution time for completed lines: 1.5 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2024-04-22 16:27:05 +0000     571 execution.bulk     INFO     The thread monitoring the process [682-ForkProcess-4:2:3] will be terminated.\n",
      "2024-04-22 16:27:05 +0000     571 execution.bulk     INFO     The thread monitoring the process [679-ForkProcess-4:2:2] will be terminated.\n",
      "2024-04-22 16:27:05 +0000     571 execution.bulk     INFO     The thread monitoring the process [672-ForkProcess-4:2:1] will be terminated.\n",
      "2024-04-22 16:27:05 +0000     571 execution.bulk     INFO     The thread monitoring the process [687-ForkProcess-4:2:4] will be terminated.\n",
      "2024-04-22 16:27:05 +0000     682 execution.bulk     INFO     The process [682] has received a terminate signal.\n",
      "2024-04-22 16:27:05 +0000     679 execution.bulk     INFO     The process [679] has received a terminate signal.\n",
      "2024-04-22 16:27:05 +0000     672 execution.bulk     INFO     The process [672] has received a terminate signal.\n",
      "2024-04-22 16:27:05 +0000     687 execution.bulk     INFO     The process [687] has received a terminate signal.\n",
      "2024-04-22 16:27:06 +0000     571 execution.bulk     INFO     Executing aggregation nodes...\n",
      "2024-04-22 16:27:06 +0000     571 execution.bulk     INFO     Finish executing aggregation nodes.\n",
      "2024-04-22 16:27:06 +0000     571 promptflow-runtime INFO     Post processing batch result...\n",
      "2024-04-22 16:27:08 +0000     571 execution.bulk     INFO     Upload status summary metrics for run rag_flow_grid_step_4_eval_eval_20240422_122637 finished in 2.017996031000166 seconds\n",
      "2024-04-22 16:27:08 +0000     571 execution.bulk     INFO     Upload metrics for run rag_flow_grid_step_4_eval_eval_20240422_122637 finished in 0.4005223340000157 seconds\n",
      "2024-04-22 16:27:08 +0000     571 promptflow-runtime INFO     Successfully write run properties {\"azureml.promptflow.total_tokens\": 0, \"_azureml.evaluate_artifacts\": \"[{\\\"path\\\": \\\"instance_results.jsonl\\\", \\\"type\\\": \\\"table\\\"}]\"} with run id 'rag_flow_grid_step_4_eval_eval_20240422_122637'\n",
      "2024-04-22 16:27:08 +0000     571 execution.bulk     INFO     Upload RH properties for run rag_flow_grid_step_4_eval_eval_20240422_122637 finished in 0.07295937900016725 seconds\n",
      "2024-04-22 16:27:08 +0000     571 promptflow-runtime INFO     Creating Artifact for Run rag_flow_grid_step_4_eval_eval_20240422_122637...\n",
      "2024-04-22 16:27:08 +0000     571 promptflow-runtime INFO     Created instance_results.jsonl Artifact.\n",
      "2024-04-22 16:27:08 +0000     571 promptflow-runtime INFO     Ending the aml run 'rag_flow_grid_step_4_eval_eval_20240422_122637' with status 'Completed'...\n",
      "======= Run Summary =======\n",
      "Run name: \"rag_flow_grid_step_4_eval_eval_20240422_122637\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2024-04-22 16:26:58.550693+00:00\"\n",
      "Duration: \"0:00:10.532905\"\n",
      "Run url: \"https://ml.azure.com/runs/rag_flow_grid_step_4_eval_eval_20240422_122637?wsid=/subscriptions/6c065ea7-65cd-4a34-8e2a-3e21ad4a8e9f/resourcegroups/vince-rg/providers/Microsoft.MachineLearningServices/workspaces/vince-dev\""
     ]
    }
   ],
   "source": [
    "from promptflow.entities import Run\n",
    "import datetime \n",
    "\n",
    "data=\"azureml://subscriptions/6c065ea7-65cd-4a34-8e2a-3e21ad4a8e9f/resourcegroups/vince-rg/workspaces/vince-dev/datastores/workspaceblobstore/paths/promptflow/PromptFlowArtifacts/rag_flow_grid_step_4_variant_0_20240422_112227_503149/instance_results.jsonl\"\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "experiment_name = \"rag_flow_grid_step_4_eval\"\n",
    "eval_run = Run(\n",
    "                flow='../flows/evaluation_flow',\n",
    "                data='../evaluation_data/data.jsonl',\n",
    "                run=\"rag_flow_grid_step_4_variant_0_20240422_112227_503149\",\n",
    "                column_mapping={\n",
    "                    \"answer\": \"${run.outputs.response}\",\n",
    "                    \"ground_truth\": \"${data.ground_truth}\"         },\n",
    "                # un-comment the resources parameter assignment\n",
    "                # and update the size of the compute and also\n",
    "                # comment the runtime parameter assignment to\n",
    "                # enable automatic runtime.\n",
    "                # Reference: COMPUTE_RUNTIME\n",
    "                # resources={\"instance_type\": \"Standard_E4ds_v4\"},\n",
    "                name=f\"{experiment_name}_eval_{timestamp}\",\n",
    "                display_name=f\"{experiment_name}_eval_{timestamp}\",\n",
    "            )\n",
    "#eval_run._experiment_name = experiment_name\n",
    "eval_job = pf.runs.create_or_update(eval_run, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1_score': 0.12}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.get_metrics(eval_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'from promptflow import tool' is deprecated and will be removed in the future. Use 'from promptflow.core import tool' instead.\n",
      "WARNING:root:'from promptflow import log_metric' is deprecated and will be removed in the future. Use 'from promptflow.core import log_metric' instead.\n",
      "[2024-04-22 13:51:50,581][promptflow][WARNING] - You're using automatic runtime, if it's first time you're using it, it may take a while to build runtime and you may see 'NotStarted' status for a while. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portal url: https://ml.azure.com/runs/rag_flow_grid_step_4_eval_eval_20240422_135149?wsid=/subscriptions/6c065ea7-65cd-4a34-8e2a-3e21ad4a8e9f/resourcegroups/vince-rg/providers/Microsoft.MachineLearningServices/workspaces/vince-dev\n",
      "(Run status is 'NotStarted', continue streaming...)\n",
      "(Run status is 'NotStarted', continue streaming...)\n",
      "(Run status is 'NotStarted', continue streaming...)\n",
      "(Run status is 'NotStarted', continue streaming...)\n",
      "(Run status is 'NotStarted', continue streaming...)\n",
      "(Run status is 'NotStarted', continue streaming...)\n",
      "(Run status is 'NotStarted', continue streaming...)\n",
      "2024-04-22 17:56:08 +0000      51 promptflow-runtime INFO     [rag_flow_grid_step_4_eval_eval_20240422_135149] Receiving v2 bulk run request ab41a9e9-b723-4c63-b793-40a506eef9e6: {\"flow_id\": \"rag_flow_grid_step_4_eval_eval_20240422_135149\", \"flow_run_id\": \"rag_flow_grid_step_4_eval_eval_20240422_135149\", \"flow_source\": {\"flow_source_type\": 1, \"flow_source_info\": {\"snapshot_id\": \"f03ff8db-37ea-448f-b10e-5e51bab23f38\"}, \"flow_dag_file\": \"flow.dag.yaml\"}, \"log_path\": \"https://vincedev4106797923.blob.core.windows.net/azureml/ExperimentRun/dcid.rag_flow_grid_step_4_eval_eval_20240422_135149/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=**data_scrubbed**&skoid=4af85c54-3f14-4b6a-a706-a4a6e971c4e7&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2024-04-22T13%3A05%3A45Z&ske=2024-04-23T21%3A15%3A45Z&sks=b&skv=2019-07-07&st=2024-04-22T17%3A45%3A48Z&se=2024-04-23T01%3A55%3A48Z&sp=rcw\", \"app_insights_instrumentation_key\": \"InstrumentationKey=**data_scrubbed**;IngestionEndpoint=https://eastus-6.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/\", \"flow_name\": \"rag_flow_grid_step_4_eval_eval_20240422_135149\", \"batch_timeout_sec\": 36000, \"data_inputs\": {\"data\": \"azureml://datastores/workspaceblobstore/paths/LocalUpload/8381842cdd004ce41a740844a5146deb/data.jsonl\", \"run.outputs\": \"azureml:/subscriptions/6c065ea7-65cd-4a34-8e2a-3e21ad4a8e9f/resourceGroups/vince-rg/providers/Microsoft.MachineLearningServices/workspaces/vince-dev/data/azureml_rag_flow_grid_step_4_variant_0_20240422_112227_503149_output_data_flow_outputs/versions/1\"}, \"inputs_mapping\": {\"answer\": \"${run.outputs.response}\", \"ground_truth\": \"${data.ground_truth}\"}, \"azure_storage_setting\": {\"azure_storage_mode\": 1, \"storage_account_name\": \"vincedev4106797923\", \"blob_container_name\": \"azureml-blobstore-6184be4d-8f14-4f56-b031-56a6ec3813fc\", \"flow_artifacts_root_path\": \"promptflow/PromptFlowArtifacts/rag_flow_grid_step_4_eval_eval_20240422_135149\", \"blob_container_sas_token\": \"?sv=2019-07-07&sr=c&sig=**data_scrubbed**&skoid=4af85c54-3f14-4b6a-a706-a4a6e971c4e7&sktid=16b3c013-d300-468d-ac64-7eda0820b6d3&skt=2024-04-22T17%3A55%3A49Z&ske=2024-04-29T17%3A55%3A49Z&sks=b&skv=2019-07-07&se=2024-04-29T17%3A55%3A49Z&sp=racwl\", \"output_datastore_name\": \"workspaceblobstore\"}, \"variant_run_id\": \"rag_flow_grid_step_4_variant_0_20240422_112227_503149\"}\n",
      "2024-04-22 17:56:08 +0000      51 promptflow-runtime INFO     Runtime version: 20240411.v4. PromptFlow version: 1.8.0rc3\n",
      "2024-04-22 17:56:08 +0000      51 promptflow-runtime INFO     Updating rag_flow_grid_step_4_eval_eval_20240422_135149 to Status.Preparing...\n",
      "2024-04-22 17:56:09 +0000      51 promptflow-runtime INFO     Downloading snapshot to /mnt/host/service/app/37537/requests/rag_flow_grid_step_4_eval_eval_20240422_135149\n",
      "2024-04-22 17:56:09 +0000      51 promptflow-runtime INFO     Get snapshot sas url for f03ff8db-37ea-448f-b10e-5e51bab23f38.\n",
      "2024-04-22 17:56:09 +0000      51 promptflow-runtime INFO     Snapshot f03ff8db-37ea-448f-b10e-5e51bab23f38 contains 37 files.\n",
      "2024-04-22 17:56:10 +0000      51 promptflow-runtime INFO     Download snapshot f03ff8db-37ea-448f-b10e-5e51bab23f38 completed.\n",
      "2024-04-22 17:56:10 +0000      51 promptflow-runtime INFO     Successfully download snapshot to /mnt/host/service/app/37537/requests/rag_flow_grid_step_4_eval_eval_20240422_135149\n",
      "2024-04-22 17:56:10 +0000      51 promptflow-runtime INFO     About to execute a python flow.\n",
      "2024-04-22 17:56:10 +0000      51 promptflow-runtime INFO     Use spawn method to start child process.\n",
      "2024-04-22 17:56:10 +0000      51 promptflow-runtime INFO     Starting to check process 291 status for run rag_flow_grid_step_4_eval_eval_20240422_135149\n",
      "2024-04-22 17:56:10 +0000      51 promptflow-runtime INFO     Start checking run status for run rag_flow_grid_step_4_eval_eval_20240422_135149\n",
      "(Run status is 'Running', continue streaming...)\n",
      "2024-04-22 17:56:19 +0000     291 promptflow-runtime INFO     [51--291] Start processing flowV2......\n",
      "2024-04-22 17:56:19 +0000     291 promptflow-runtime INFO     Runtime version: 20240411.v4. PromptFlow version: 1.8.0rc3\n",
      "2024-04-22 17:56:19 +0000     291 promptflow-runtime INFO     Setting mlflow tracking uri...\n",
      "2024-04-22 17:56:19 +0000     291 promptflow-runtime INFO     Validating 'AzureML Data Scientist' user authentication...\n",
      "2024-04-22 17:56:20 +0000     291 promptflow-runtime INFO     Successfully validated 'AzureML Data Scientist' user authentication.\n",
      "2024-04-22 17:56:20 +0000     291 promptflow-runtime INFO     Using AzureMLRunStorageV2\n",
      "2024-04-22 17:56:20 +0000     291 promptflow-runtime INFO     Setting mlflow tracking uri to 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/6c065ea7-65cd-4a34-8e2a-3e21ad4a8e9f/resourceGroups/vince-rg/providers/Microsoft.MachineLearningServices/workspaces/vince-dev'\n",
      "2024-04-22 17:56:20 +0000     291 promptflow-runtime INFO     Setting mlflow tracking uri to 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/6c065ea7-65cd-4a34-8e2a-3e21ad4a8e9f/resourceGroups/vince-rg/providers/Microsoft.MachineLearningServices/workspaces/vince-dev'\n",
      "2024-04-22 17:56:20 +0000     291 promptflow-runtime INFO     Creating unregistered output Asset for Run rag_flow_grid_step_4_eval_eval_20240422_135149...\n",
      "2024-04-22 17:56:20 +0000     291 promptflow-runtime INFO     Created debug_info Asset: azureml://locations/eastus/workspaces/6184be4d-8f14-4f56-b031-56a6ec3813fc/data/azureml_rag_flow_grid_step_4_eval_eval_20240422_135149_output_data_debug_info/versions/1\n",
      "2024-04-22 17:56:20 +0000     291 promptflow-runtime INFO     Creating unregistered output Asset for Run rag_flow_grid_step_4_eval_eval_20240422_135149...\n",
      "2024-04-22 17:56:20 +0000     291 promptflow-runtime INFO     Created flow_outputs output Asset: azureml://locations/eastus/workspaces/6184be4d-8f14-4f56-b031-56a6ec3813fc/data/azureml_rag_flow_grid_step_4_eval_eval_20240422_135149_output_data_flow_outputs/versions/1\n",
      "2024-04-22 17:56:20 +0000     291 promptflow-runtime INFO     Patching rag_flow_grid_step_4_eval_eval_20240422_135149...\n",
      "2024-04-22 17:56:21 +0000     291 promptflow-runtime INFO     Resolve data from url finished in 0.9097047100000282 seconds\n",
      "2024-04-22 17:56:22 +0000     291 promptflow-runtime INFO     Resolve data from url finished in 1.065442796999946 seconds\n",
      "2024-04-22 17:56:23 +0000     291 promptflow-runtime INFO     Starting the aml run 'rag_flow_grid_step_4_eval_eval_20240422_135149'...\n",
      "2024-04-22 17:56:23 +0000     291 execution.bulk     INFO     The timeout for the batch run is 36000 seconds.\n",
      "2024-04-22 17:56:23 +0000     291 execution.bulk     INFO     Set process count to 4 by taking the minimum value among the factors of {'default_worker_count': 4, 'row_count': 4}.\n",
      "2024-04-22 17:56:30 +0000     291 execution.bulk     INFO     Process name(ForkProcess-6:2:4)-Process id(618)-Line number(3) start execution.\n",
      "2024-04-22 17:56:30 +0000     291 execution.bulk     INFO     Process name(ForkProcess-6:2:2)-Process id(604)-Line number(2) start execution.\n",
      "2024-04-22 17:56:30 +0000     291 execution.bulk     INFO     Process name(ForkProcess-6:2:1)-Process id(595)-Line number(0) start execution.\n",
      "2024-04-22 17:56:30 +0000     291 execution.bulk     INFO     Process name(ForkProcess-6:2:3)-Process id(611)-Line number(1) start execution.\n",
      "2024-04-22 17:56:30 +0000     291 execution.bulk     INFO     Process name(ForkProcess-6:2:3)-Process id(611)-Line number(1) completed.\n",
      "2024-04-22 17:56:30 +0000     291 execution.bulk     INFO     Process name(ForkProcess-6:2:2)-Process id(604)-Line number(2) completed.\n",
      "2024-04-22 17:56:30 +0000     291 execution.bulk     INFO     Process name(ForkProcess-6:2:1)-Process id(595)-Line number(0) completed.\n",
      "2024-04-22 17:56:30 +0000     291 execution.bulk     INFO     Process name(ForkProcess-6:2:4)-Process id(618)-Line number(3) completed.\n",
      "2024-04-22 17:56:30 +0000     291 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2024-04-22 17:56:31 +0000     291 execution.bulk     INFO     Average execution time for completed lines: 1.75 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2024-04-22 17:56:31 +0000     291 execution.bulk     INFO     The thread monitoring the process [611-ForkProcess-6:2:3] will be terminated.\n",
      "2024-04-22 17:56:31 +0000     291 execution.bulk     INFO     The thread monitoring the process [604-ForkProcess-6:2:2] will be terminated.\n",
      "2024-04-22 17:56:31 +0000     291 execution.bulk     INFO     The thread monitoring the process [595-ForkProcess-6:2:1] will be terminated.\n",
      "2024-04-22 17:56:31 +0000     291 execution.bulk     INFO     The thread monitoring the process [618-ForkProcess-6:2:4] will be terminated.\n",
      "2024-04-22 17:56:31 +0000     611 execution.bulk     INFO     The process [611] has received a terminate signal.\n",
      "2024-04-22 17:56:31 +0000     604 execution.bulk     INFO     The process [604] has received a terminate signal.\n",
      "2024-04-22 17:56:31 +0000     595 execution.bulk     INFO     The process [595] has received a terminate signal.\n",
      "2024-04-22 17:56:31 +0000     618 execution.bulk     INFO     The process [618] has received a terminate signal.\n",
      "2024-04-22 17:56:32 +0000     291 execution.bulk     INFO     Executing aggregation nodes...\n",
      "2024-04-22 17:56:32 +0000     291 execution.bulk     INFO     Finish executing aggregation nodes.\n",
      "2024-04-22 17:56:32 +0000     291 promptflow-runtime INFO     Post processing batch result...\n",
      "2024-04-22 17:56:34 +0000     291 execution.bulk     INFO     Upload status summary metrics for run rag_flow_grid_step_4_eval_eval_20240422_135149 finished in 1.8447326650000377 seconds\n",
      "2024-04-22 17:56:34 +0000     291 execution.bulk     INFO     Upload metrics for run rag_flow_grid_step_4_eval_eval_20240422_135149 finished in 0.29181005500004176 seconds\n",
      "2024-04-22 17:56:34 +0000     291 promptflow-runtime INFO     Successfully write run properties {\"azureml.promptflow.total_tokens\": 0, \"_azureml.evaluate_artifacts\": \"[{\\\"path\\\": \\\"instance_results.jsonl\\\", \\\"type\\\": \\\"table\\\"}]\"} with run id 'rag_flow_grid_step_4_eval_eval_20240422_135149'\n",
      "2024-04-22 17:56:34 +0000     291 execution.bulk     INFO     Upload RH properties for run rag_flow_grid_step_4_eval_eval_20240422_135149 finished in 0.07528864999994767 seconds\n",
      "2024-04-22 17:56:34 +0000     291 promptflow-runtime INFO     Creating Artifact for Run rag_flow_grid_step_4_eval_eval_20240422_135149...\n",
      "2024-04-22 17:56:34 +0000     291 promptflow-runtime INFO     Created instance_results.jsonl Artifact.\n",
      "2024-04-22 17:56:34 +0000     291 promptflow-runtime INFO     Ending the aml run 'rag_flow_grid_step_4_eval_eval_20240422_135149' with status 'Completed'...\n",
      "======= Run Summary =======\n",
      "Run name: \"rag_flow_grid_step_4_eval_eval_20240422_135149\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2024-04-22 17:56:23.546357+00:00\"\n",
      "Duration: \"0:00:11.248661\"\n",
      "Run url: \"https://ml.azure.com/runs/rag_flow_grid_step_4_eval_eval_20240422_135149?wsid=/subscriptions/6c065ea7-65cd-4a34-8e2a-3e21ad4a8e9f/resourcegroups/vince-rg/providers/Microsoft.MachineLearningServices/workspaces/vince-dev\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "<promptflow._sdk.entities._run.Run at 0x7fbfd54d96d0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "run = pf.run(\n",
    "            flow='../flows/evaluation_flow',\n",
    "                data='../evaluation_data/data.jsonl',\n",
    "                run=\"rag_flow_grid_step_4_variant_0_20240422_112227_503149\",\n",
    "                column_mapping={\n",
    "                    \"answer\": \"${run.outputs.response}\",\n",
    "                    \"ground_truth\": \"${data.ground_truth}\"         },\n",
    "                # un-comment the resources parameter assignment\n",
    "                # and update the size of the compute and also\n",
    "                # comment the runtime parameter assignment to\n",
    "                # enable automatic runtime.\n",
    "                # Reference: COMPUTE_RUNTIME\n",
    "                # resources={\"instance_type\": \"Standard_E4ds_v4\"},\n",
    "                name=f\"{experiment_name}_eval_{timestamp}\",\n",
    "                display_name=f\"{experiment_name}_eval_{timestamp}\",\n",
    "        )\n",
    "\n",
    "pf.stream(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[43mraw_input\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is your name\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'raw_input' is not defined"
     ]
    }
   ],
   "source": [
    "e = raw_input(\"what is your name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
