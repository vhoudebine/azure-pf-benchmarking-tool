{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "with open('sweep_definition.yaml', 'r') as file:\n",
    "    sweep_config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def flatten_dict(variant_dict):\n",
    "    variant_name = list(variant_dict.keys())[0]\n",
    "    variant_values = variant_dict[variant_name]\n",
    "    result_dict = {'variant_name': variant_name}\n",
    "    result_dict.update(variant_values)\n",
    "    return result_dict\n",
    "\n",
    "def cartesian_product(*lists):\n",
    "    cartesian_product = []\n",
    "    for items in itertools.product(*lists):\n",
    "        merged_dict = {}\n",
    "        for item in items:\n",
    "            merged_dict.update(item)\n",
    "        cartesian_product.append(merged_dict)\n",
    "    return cartesian_product\n",
    "\n",
    "def duplicate_dict(dictionary):\n",
    "    result = [dictionary]\n",
    "    for key, value in dictionary.items():\n",
    "        if isinstance(value, list):\n",
    "            temp_result = []\n",
    "            for item in value:\n",
    "                for res in result:\n",
    "                    temp_dict = res.copy()\n",
    "                    temp_dict[key] = item\n",
    "                    temp_result.append(temp_dict)\n",
    "            result = temp_result\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "search_space =[]\n",
    "for node in sweep_config.get('search_space'):\n",
    "    if node in ['llm','embedding','vector_store']:\n",
    "        grid = []\n",
    "        node_values = sweep_config.get('search_space').get(node)\n",
    "        for variant in node_values:\n",
    "            step_dict ={}\n",
    "            step_dict[node] = flatten_dict(variant)\n",
    "            grid.append(step_dict)\n",
    "        grid_final = []\n",
    "        for step in grid:\n",
    "            \n",
    "            node_id = list(step.keys())[0]    \n",
    "            fixed = {key:value for key,value in step.get(node_id).items() if not isinstance(value, dict)}\n",
    "            for key, value in step.get(node_id).items():\n",
    "                option_list =[]\n",
    "                if isinstance(value, dict):\n",
    "                    options = duplicate_dict(value)\n",
    "                    for option in options:\n",
    "                        f = deepcopy(fixed)\n",
    "                        f[key] = option.get('values')\n",
    "                        option_list.append(f)    \n",
    "            \n",
    "            if len(option_list)>1:\n",
    "                for opt in option_list:\n",
    "                    grid_final.append({node_id: opt})\n",
    "            else:\n",
    "                grid_final.append({node_id: fixed})\n",
    "        search_space.append(grid_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_steps = cartesian_product(*search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llm': {'variant_name': 'mistral',\n",
       "  'family': 'MISTRAL',\n",
       "  'connection': 'mistral-large-maas'},\n",
       " 'embedding': {'variant_name': 'aoai',\n",
       "  'family': 'AZUREOPENAI',\n",
       "  'connection': 'aoai',\n",
       "  'deployment': 'text-embedding-ada-002'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_steps[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "\n",
    "file_path = \"./rag_flow_template/cookiecutter_template.json\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blush_fly_z3ktl6dy\n"
     ]
    }
   ],
   "source": [
    "from unique_names_generator import get_random_name\n",
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "def generate_step_id():\n",
    "    name = get_random_name(separator=\"_\", style=\"lowercase\")\n",
    "    unique_id = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))\n",
    "    return name+'_'+ unique_id\n",
    "\n",
    "# Generate a unique ID\n",
    "unique_id = generate_step_id()\n",
    "print(unique_id)\n",
    "\n",
    "\n",
    "def create_cookiecutter(data, grid_step):\n",
    "    data_dict = deepcopy(data)\n",
    "    for node_id in data_dict:\n",
    "        if node_id in ['llm','embedding','vector_store'] and node_id in grid_step.keys():\n",
    "            data_dict[node_id]=grid_step[node_id]\n",
    "        elif node_id in ['llm','embedding','vector_store'] and node_id not in grid_step.keys():\n",
    "            del data_dict[node_id]\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_path = \"./rag_flow_template/cookiecutter.json\"\n",
    "\n",
    "for i, search_step_dict in enumerate(grid_search_steps):\n",
    "    directory = 'flow_versions'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    step_dict = create_cookiecutter(data, search_step_dict)\n",
    "    step_dict[\"flow_name\"] = f\"grid_step_{i}\"\n",
    "    \n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(step_dict, file, indent=4)\n",
    "    \n",
    "    subprocess.run([\"cd ./flow_versions && cookiecutter ../rag_flow_template --no-input --skip-if-file-exists\"], shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/vhoudebine/config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from promptflow.azure import PFClient\n",
    "\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "  \n",
    "# Get a handle to workspace, it will use config.json in current and parent directory.\n",
    "pf = PFClient.from_config(\n",
    "    credential=credential,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating run for ./flow_versions/rag_flow_grid_step_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading rag_flow_grid_step_0 (0.0 MBs): 100%|██████████| 514/514 [00:00<00:00, 4185.59it/s]\n",
      "\u001b[39m\n",
      "\n",
      "[2024-04-04 20:04:31,062][promptflow][WARNING] - You're using automatic runtime, if it's first time you're using it, it may take a while to build runtime and you may see 'NotStarted' status for a while. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portal url: https://ml.azure.com/runs/rag_flow_grid_step_0_variant_0_20240404_200429_297972?wsid=/subscriptions/6c065ea7-65cd-4a34-8e2a-3e21ad4a8e9f/resourcegroups/vince-rg/providers/Microsoft.MachineLearningServices/workspaces/vince-dev\n",
      "Created run rag_flow_grid_step_0_variant_0_20240404_200429_297972\n",
      "Creating run for ./flow_versions/rag_flow_grid_step_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-04 20:04:42,410][promptflow][WARNING] - You're using automatic runtime, if it's first time you're using it, it may take a while to build runtime and you may see 'NotStarted' status for a while. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portal url: https://ml.azure.com/runs/rag_flow_grid_step_1_variant_0_20240404_200441_308304?wsid=/subscriptions/6c065ea7-65cd-4a34-8e2a-3e21ad4a8e9f/resourcegroups/vince-rg/providers/Microsoft.MachineLearningServices/workspaces/vince-dev\n",
      "Created run rag_flow_grid_step_1_variant_0_20240404_200441_308304\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_and_run_flow(i):\n",
    "    # Apply your function to the dictionary here\n",
    "    flow = os.path.join(\"./flow_versions\", f\"rag_flow_grid_step_{i}\")\n",
    "    data =\"./evaluation_data/data.jsonl\"\n",
    "    print(f\"Creating run for {flow}\")\n",
    "    # create run\n",
    "    base_run = pf.run(\n",
    "        flow=flow,\n",
    "        data=data,\n",
    "        column_mapping={\n",
    "        \"question\": \"${data.question}\"\n",
    "        }\n",
    "    )\n",
    "    print(f\"Created run {base_run.name}\")\n",
    "    return base_run\n",
    "\n",
    "\n",
    "# Create a thread for each dictionary\n",
    "runs = []\n",
    "for i, search_step_dict in enumerate(grid_search_steps):\n",
    "    run = create_and_run_flow(i)\n",
    "    runs.append(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = runs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
